{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUZXYXeFDFOI"
   },
   "source": [
    "# Custom Object Detection\n",
    "## Colab Trainer\n",
    "\n",
    "This notebook is for training your custom model after running [this](https://github.com/theneuralbeing/object_detection_template/blob/master/data_preprocessing/Preprocess_Data.ipynb) notebook locally on your computer which generates the tf record files for your custom dataset. You can run all these cells in order and follow the steps written as comments and markdown cells along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJEMVvKgHYMo"
   },
   "source": [
    "Colab VM Project Structure\n",
    "\n",
    "```\n",
    "content/\n",
    "        ├─ data/\n",
    "        │    ├── label_map.pbtxt\n",
    "        │    ├── test.record\n",
    "        │    └── train.record\n",
    "        └─ models/\n",
    "             ├─ research/\n",
    "             │      ├── fine_tuned_model/\n",
    "             │      │         ├── frozen_inference_graph.pb\n",
    "             │      │         └── ...\n",
    "             │      │         \n",
    "             │      ├── pretrained_model/\n",
    "             │      │         ├── frozen_inference_graph.pb\n",
    "             │      │         └── ...\n",
    "             │      │         \n",
    "             │      ├── object_detection/\n",
    "             │      │         ├── utils/\n",
    "             │      │         ├── samples/\n",
    "             │      │         │      ├── samples/ \n",
    "             │      │         │      │       ├── configs/             \n",
    "             │      │         │      │       │     ├── ssd_mobilenet_v2_coco.config\n",
    "             │      │         │      │       │     ├── rfcn_resnet101_pets.config\n",
    "             │      │         │      │       │     └── ...\n",
    "             │      │         │      │       └── ... \n",
    "             │      │         │      └── ...                                \n",
    "             │      │         ├── export_inference_graph.py\n",
    "             │      │         ├── model_main.py\n",
    "             │      │         └── ...\n",
    "             │      │         \n",
    "             │      ├── training/\n",
    "             │      │         ├── events.out.tfevents.xxxxx\n",
    "             │      │         └── ...               \n",
    "             │      └── ...\n",
    "             └── ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhOmXekWIGON"
   },
   "source": [
    "## Installing Prerequisites and Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5uF6UG8IIo0"
   },
   "outputs": [],
   "source": [
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "\n",
    "!pip install -qq Cython contextlib2 pillow lxml matplotlib\n",
    "\n",
    "!pip install -qq pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUmCIgQuINJY"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import cv2 \n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import io\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from PIL import Image\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import shutil\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZMq86mFISey"
   },
   "outputs": [],
   "source": [
    "# Object Detection API works in Tensorflow v 1.15 (it is remove in v 2.0)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4y_01gbpI2MV"
   },
   "source": [
    "## Getting preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lo8RedKFJGDI"
   },
   "outputs": [],
   "source": [
    "# Upload your data.zip file which contains the record files and label map\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHKyMnWWIo3u"
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!unzip data.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bF25eVB2NFJQ"
   },
   "source": [
    "## Downloading and Installing Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zj2WAYyyNEU8"
   },
   "outputs": [],
   "source": [
    "# Downlaods Tensorflow Object Detection API\n",
    "%cd /content\n",
    "!git clone --q https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XpzvxKQgNSsd"
   },
   "outputs": [],
   "source": [
    "%cd /content/models/research\n",
    "#compiling the proto buffers (not important to understand for this project but you can learn more about them here: https://developers.google.com/protocol-buffers/)\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "# exports the PYTHONPATH environment variable with the reasearch and slim folders' paths\n",
    "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gg9wxBvjNVKH"
   },
   "outputs": [],
   "source": [
    "# testing the model builder\n",
    "!python3 object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pR2350wlMo5E"
   },
   "source": [
    "## Getting the pretrained model\n",
    "\n",
    "Check other models from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5k8_31DiMoo3"
   },
   "outputs": [],
   "source": [
    "# Some models to train on\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select a model in `MODELS_CONFIG`.\n",
    "selected_model = 'ssd_mobilenet_v2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJTbelkjLebq"
   },
   "outputs": [],
   "source": [
    "%cd /content/models/research\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "#selecting the model\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "\n",
    "#creating the downlaod link for the model selected\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "#the distination folder where the model will be saved\n",
    "fine_tune_dir = '/content/models/research/pretrained_model'\n",
    "\n",
    "#checks if the model has already been downloaded\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "#unzipping the file and extracting its content\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# creating an output file to save the model while training\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(fine_tune_dir)):\n",
    "    shutil.rmtree(fine_tune_dir)\n",
    "os.rename(MODEL, fine_tune_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7mB0qhVTD3C"
   },
   "outputs": [],
   "source": [
    "# checking the content of the pretrained model.\n",
    "# this is the directory of the \"fine_tune_checkpoint\" that is used in the config file.\n",
    "!echo {fine_tune_dir}\n",
    "!ls -alh {fine_tune_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WgOmv1bTJBB"
   },
   "source": [
    "## Configuring Training Pipeline\n",
    "\n",
    "Editing the configuration file to add the path for the TFRecords files, pbtxt,  batch_size, num_steps, num_classes.\n",
    "\n",
    "Any image augmentation, hyperparemeter tunning (drop out, batch normalization... etc) can be editted here in the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIv1-_XWVaB1"
   },
   "outputs": [],
   "source": [
    "#the path to the folder containing all the sample config files\n",
    "CONFIG_BASE = \"/content/models/research/object_detection/samples/configs/\"\n",
    "\n",
    "#path to the specified model's config file\n",
    "model_pipline = os.path.join(CONFIG_BASE, pipeline_file)\n",
    "model_pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xW0g3H3pTY1z"
   },
   "outputs": [],
   "source": [
    "%%writefile {model_pipline}\n",
    "\n",
    "model {\n",
    "  ssd {\n",
    "    num_classes: 1 # number of classes to be detected\n",
    "    box_coder {\n",
    "      faster_rcnn_box_coder {\n",
    "        y_scale: 10.0\n",
    "        x_scale: 10.0\n",
    "        height_scale: 5.0\n",
    "        width_scale: 5.0\n",
    "      }\n",
    "    }\n",
    "    matcher {\n",
    "      argmax_matcher {\n",
    "        matched_threshold: 0.5\n",
    "        unmatched_threshold: 0.5\n",
    "        ignore_thresholds: false\n",
    "        negatives_lower_than_unmatched: true\n",
    "        force_match_for_each_row: true\n",
    "      }\n",
    "    }\n",
    "    similarity_calculator {\n",
    "      iou_similarity {\n",
    "      }\n",
    "    }\n",
    "    anchor_generator {\n",
    "      ssd_anchor_generator {\n",
    "        num_layers: 6\n",
    "        min_scale: 0.2\n",
    "        max_scale: 0.95\n",
    "        aspect_ratios: 1.0\n",
    "        aspect_ratios: 2.0\n",
    "        aspect_ratios: 0.5\n",
    "        aspect_ratios: 3.0\n",
    "        aspect_ratios: 0.3333\n",
    "      }\n",
    "    }\n",
    "    # all images will be resized to the below W x H.\n",
    "    image_resizer { \n",
    "      fixed_shape_resizer {\n",
    "        height: 300\n",
    "        width: 300\n",
    "      }\n",
    "    }\n",
    "    box_predictor {\n",
    "      convolutional_box_predictor {\n",
    "        min_depth: 0\n",
    "        max_depth: 0\n",
    "        num_layers_before_predictor: 0\n",
    "        use_dropout: true # to counter over fitting. you can also try tweaking its probability below\n",
    "        dropout_keep_probability: 0.8\n",
    "        kernel_size: 1\n",
    "        box_code_size: 4\n",
    "        apply_sigmoid_to_scores: false\n",
    "        conv_hyperparams {\n",
    "          activation: RELU_6,\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "            # weight: 0.00004\n",
    "            weight: 0.001 # higher regularizition to counter overfitting\n",
    "          }\n",
    "          }\n",
    "          initializer {\n",
    "            truncated_normal_initializer {\n",
    "              stddev: 0.03\n",
    "              mean: 0.0\n",
    "            }\n",
    "          }\n",
    "          batch_norm {\n",
    "            train: true,\n",
    "            scale: true,\n",
    "            center: true,\n",
    "            decay: 0.9997,\n",
    "            epsilon: 0.001,\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    feature_extractor {\n",
    "      type: 'ssd_mobilenet_v2'\n",
    "      min_depth: 16\n",
    "      depth_multiplier: 1.0\n",
    "      conv_hyperparams {\n",
    "        activation: RELU_6,\n",
    "        regularizer {\n",
    "          l2_regularizer {\n",
    "            # weight: 0.00004\n",
    "            weight: 0.001 # higher regularizition to counter overfitting\n",
    "          }\n",
    "        }\n",
    "        initializer {\n",
    "          truncated_normal_initializer {\n",
    "            stddev: 0.03\n",
    "            mean: 0.0\n",
    "          }\n",
    "        }\n",
    "        batch_norm {\n",
    "          train: true,\n",
    "          scale: true,\n",
    "          center: true,\n",
    "          decay: 0.9997,\n",
    "          epsilon: 0.001,\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    loss {\n",
    "      classification_loss {\n",
    "        weighted_sigmoid {\n",
    "        }\n",
    "      }\n",
    "      localization_loss {\n",
    "        weighted_smooth_l1 {\n",
    "        }\n",
    "      }\n",
    "      hard_example_miner {\n",
    "        num_hard_examples: 3000 \n",
    "        iou_threshold: 0.95\n",
    "        loss_type: CLASSIFICATION\n",
    "        max_negatives_per_positive: 3\n",
    "        min_negatives_per_image: 3\n",
    "      }\n",
    "      classification_weight: 1.0\n",
    "      localization_weight: 1.0\n",
    "    }\n",
    "    normalize_loss_by_num_matches: true\n",
    "    post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 1e-8\n",
    "        iou_threshold: 0.6\n",
    "        \n",
    "        # adjust this to the max number of objects per class.\n",
    "        max_detections_per_class: 4\n",
    "        # max number of detections among all classes\n",
    "        max_total_detections: 4\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_config: {\n",
    "  batch_size: 16 # training batch size\n",
    "  optimizer {\n",
    "    rms_prop_optimizer: {\n",
    "      learning_rate: {\n",
    "        exponential_decay_learning_rate {\n",
    "          initial_learning_rate: 0.003\n",
    "          decay_steps: 800720\n",
    "          decay_factor: 0.95\n",
    "        }\n",
    "      }\n",
    "      momentum_optimizer_value: 0.9\n",
    "      decay: 0.9\n",
    "      epsilon: 1.0\n",
    "    }\n",
    "  }\n",
    "\n",
    "  # the path to the pretrained model. \n",
    "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
    "  fine_tune_checkpoint_type:  \"detection\"\n",
    "  # edit the num_steps to your required amount of steps. Predefining steps\n",
    "  # will stop the learning rate from decaying. You can also remove the line to \n",
    "  # train indefinitely\n",
    "  # num_steps: 10000\n",
    "  \n",
    "\n",
    "  # data augmentaion is done here, you can remove or add more.\n",
    "  # They will help the model generalize but the training time will increase greatly by using more data augmentation.\n",
    "  # Check this link to add more image augmentation: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n",
    "  \n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    random_adjust_contrast {\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    ssd_random_crop {\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    #path to the training TFRecord\n",
    "    input_path: \"/content/data/train.record\"\n",
    "  }\n",
    "  #path to the label map \n",
    "  label_map_path: \"/content/data/label_map.pbtxt\"\n",
    "}\n",
    "\n",
    "eval_config: {\n",
    "  # the number of images in your \"testing\" data (was 600 but we removed one above :) )\n",
    "  num_examples: 30\n",
    "  # the number of images to disply in Tensorboard while training\n",
    "  num_visualizations: 5\n",
    "\n",
    "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
    "  # Remove the below line to evaluate indefinitely.\n",
    "  # max_evals: 10\n",
    "}\n",
    "\n",
    "eval_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "      \n",
    "    #path to the testing TFRecord\n",
    "    input_path: \"/content/data/test.record\"\n",
    "  }\n",
    "  #path to the label map \n",
    "  label_map_path: \"/content/data/label_map.pbtxt\"\n",
    "  shuffle: false\n",
    "  num_readers: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqbb6FqLVLLq"
   },
   "outputs": [],
   "source": [
    "# where the model will be saved at each checkpoint while training \n",
    "model_dir = 'training/'\n",
    "\n",
    "# Optionally: remove content in output model directory to fresh start.\n",
    "!rm -rf {model_dir}\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkcVnqEsVj0I"
   },
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdPufKfQVPnr"
   },
   "outputs": [],
   "source": [
    "# downloading ngrok to be able to access tensorboard on google colab\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2E--FZmVrYb"
   },
   "outputs": [],
   "source": [
    "# the logs that are created while training \n",
    "LOG_DIR = model_dir\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NincnSEEVt7-"
   },
   "outputs": [],
   "source": [
    "# The link to tensorboard.\n",
    "# works after the training starts.\n",
    "\n",
    "### note: if you didnt get a link as output, rerun this cell and the one above\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-vkHn73V1UD"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbIypMf3VxUv"
   },
   "outputs": [],
   "source": [
    "!python3 /content/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={model_pipline}\\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jj82A3xeV-PA"
   },
   "source": [
    "## Exporting the Trained Model as a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrvjRg3WWAWk"
   },
   "outputs": [],
   "source": [
    "# the location where the exported model will be saved in.\n",
    "output_directory = '/content/models/research/fine_tuned_model'\n",
    "\n",
    "# goes through the model is the training/ dir and gets the last one.\n",
    "# you could choose a specfic one instead of the last\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "print(last_model_path)\n",
    "\n",
    "#exports the model specifed and inference graph\n",
    "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={model_pipline} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZStl1-iAWGJF"
   },
   "outputs": [],
   "source": [
    "# download the frozen model that is needed for inference\n",
    "files.download(output_directory + '/frozen_inference_graph.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxqBLqckWNBu"
   },
   "source": [
    "## Performing Inference\n",
    "To perform inference locally on your computer, follow these steps\n",
    "\n",
    "1. Ideally create a separate environment with Tensorflow version 1.15 installed and then `pip install object_detection`\n",
    "2. Open the [`inference_webcam.py`]()\n",
    "3. Edit the path to the frozen graph in the file\n",
    "4. If you remember our label_map.pbtxt was of the format\n",
    "```\n",
    "item {\n",
    "    id: 1\n",
    "    name: 'LABEL_1'\n",
    "}\n",
    "item {\n",
    "    id: 2\n",
    "    name: 'LABEL_2'\n",
    "}\n",
    "```\n",
    "Now edit the `category_index` dictionary in the inference file in the following format\n",
    "```\n",
    "category_index = {1: {'id': 1, 'name': 'LABEL_1'}, 2: {'id': 2, 'name': 'LABEL_2'}}\n",
    "```\n",
    "5. Finally run `inference_webcam.py` in the terminal and your custom object detection model is ready."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "object_detection_training.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
